{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bc1f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T17:31:02.592476Z",
     "iopub.status.busy": "2025-10-14T17:31:02.591652Z",
     "iopub.status.idle": "2025-10-14T17:34:05.084006Z",
     "shell.execute_reply": "2025-10-14T17:34:05.083250Z"
    },
    "papermill": {
     "duration": 182.497558,
     "end_time": "2025-10-14T17:34:05.085308",
     "exception": false,
     "start_time": "2025-10-14T17:31:02.587750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4165\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 12.023362\n",
      "[200]\ttrain's rmse: 0.0685316\tvalid's rmse: 0.126226\n",
      "[400]\ttrain's rmse: 0.0458941\tvalid's rmse: 0.124729\n",
      "[600]\ttrain's rmse: 0.0339682\tvalid's rmse: 0.12452\n",
      "[800]\ttrain's rmse: 0.0262899\tvalid's rmse: 0.124661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4158\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 12.026498\n",
      "[200]\ttrain's rmse: 0.0696394\tvalid's rmse: 0.114594\n",
      "[400]\ttrain's rmse: 0.047168\tvalid's rmse: 0.111545\n",
      "[600]\ttrain's rmse: 0.0346181\tvalid's rmse: 0.111238\n",
      "[800]\ttrain's rmse: 0.0264924\tvalid's rmse: 0.111197\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4163\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 12.025399\n",
      "[200]\ttrain's rmse: 0.0675661\tvalid's rmse: 0.127181\n",
      "[400]\ttrain's rmse: 0.0448036\tvalid's rmse: 0.124757\n",
      "[600]\ttrain's rmse: 0.0327761\tvalid's rmse: 0.124383\n",
      "[800]\ttrain's rmse: 0.0254407\tvalid's rmse: 0.124205\n",
      "[1000]\ttrain's rmse: 0.0204006\tvalid's rmse: 0.124457\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4175\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 12.024512\n",
      "[200]\ttrain's rmse: 0.0677287\tvalid's rmse: 0.128118\n",
      "[400]\ttrain's rmse: 0.0464192\tvalid's rmse: 0.127236\n",
      "[600]\ttrain's rmse: 0.0346291\tvalid's rmse: 0.127593\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4167\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 12.020308\n",
      "[200]\ttrain's rmse: 0.0684939\tvalid's rmse: 0.115629\n",
      "[400]\ttrain's rmse: 0.0458132\tvalid's rmse: 0.114752\n",
      "[600]\ttrain's rmse: 0.0343134\tvalid's rmse: 0.114718\n",
      "[Blend] Best OOF RMSLE (log space): 0.11284 with LightGBM weight=0.20\n",
      "Saved: /kaggle/working/submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>117682.341437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>163881.681832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>182998.466802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>194979.855507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>184696.889100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  117682.341437\n",
       "1  1462  163881.681832\n",
       "2  1463  182998.466802\n",
       "3  1464  194979.855507\n",
       "4  1465  184696.889100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High-scoring House Prices pipeline (LightGBM + CatBoost blend, 5-fold CV)\n",
    "# Output: /kaggle/working/submission.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = Path(\"/kaggle/input/house-prices-advanced-regression-techniques\")\n",
    "train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "test  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "test_ids = test[\"Id\"].copy()\n",
    "\n",
    "# 1) Domain-aware NA handling\n",
    "none_cols = [\n",
    "    'Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "    'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond',\n",
    "    'PoolQC','Fence','MiscFeature','MasVnrType'\n",
    "]\n",
    "for df in (train, test):\n",
    "    for c in none_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"None\")\n",
    "\n",
    "for df in (train, test):\n",
    "    for c in ['MasVnrArea','BsmtFullBath','BsmtHalfBath','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "              'TotalBsmtSF','GarageYrBlt','GarageArea','GarageCars','LotFrontage','PoolArea']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(0 if c != 'GarageYrBlt' else 0)\n",
    "    for c in ['Electrical','KitchenQual','Exterior1st','Exterior2nd','SaleType','Functional']:\n",
    "        if c in df.columns and df[c].isna().any():\n",
    "            df[c] = df[c].fillna(df[c].mode()[0])\n",
    "\n",
    "# 2) Ordinal encodings\n",
    "ord_maps = {\n",
    "    'ExterQual': {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'ExterCond': {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'BsmtQual':  {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'BsmtCond':  {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'HeatingQC': {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'KitchenQual':{'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'FireplaceQu':{'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'GarageQual': {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'GarageCond': {'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5},\n",
    "    'PoolQC':     {'None':0,'Fa':1,'TA':2,'Gd':3,'Ex':4},\n",
    "    'BsmtExposure':{'None':0,'No':1,'Mn':2,'Av':3,'Gd':4},\n",
    "    'BsmtFinType1':{'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6},\n",
    "    'BsmtFinType2':{'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6},\n",
    "    'Functional': {'Sal':1,'Sev':2,'Maj2':3,'Maj1':4,'Mod':5,'Min2':6,'Min1':7,'Typ':8},\n",
    "    'PavedDrive': {'N':0,'P':1,'Y':2},\n",
    "}\n",
    "for col, mp in ord_maps.items():\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].map(mp).astype(\"Int64\")\n",
    "        test[col]  = test[col].map(mp).astype(\"Int64\")\n",
    "\n",
    "# 3) Feature engineering\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"TotalSF\"]   = df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n",
    "    df[\"TotalPorchSF\"] = df[[\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"WoodDeckSF\"]].sum(axis=1)\n",
    "    df[\"TotalBath\"] = df[\"FullBath\"] + 0.5*df[\"HalfBath\"] + df[\"BsmtFullBath\"] + 0.5*df[\"BsmtHalfBath\"]\n",
    "    df[\"HouseAge\"]  = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "    df[\"RemodAge\"]  = df[\"YrSold\"] - df[\"YearRemodAdd\"]\n",
    "    df[\"IsRemod\"]   = (df[\"YearBuilt\"] != df[\"YearRemodAdd\"]).astype(int)\n",
    "    df[\"GarageAge\"] = np.where(df[\"GarageYrBlt\"]>0, df[\"YrSold\"] - df[\"GarageYrBlt\"], -1)\n",
    "    if \"OverallQual\" in df.columns:\n",
    "        df[\"Qual_SF\"] = df[\"OverallQual\"] * np.log1p(df[\"TotalSF\"])\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test  = add_features(test)\n",
    "\n",
    "# Outlier removal\n",
    "out_idx = train[(train[\"GrLivArea\"]>4000) & (train[\"SalePrice\"]<300000)].index\n",
    "train = train.drop(index=out_idx).reset_index(drop=True)\n",
    "\n",
    "# 4) Matrices\n",
    "y_log = np.log1p(train[\"SalePrice\"].values)\n",
    "train = train.drop(columns=[\"SalePrice\"])\n",
    "X_full = train.drop(columns=[\"Id\"])\n",
    "X_test = test.drop(columns=[\"Id\"])\n",
    "\n",
    "# Make non-ordinal object columns categorical\n",
    "def make_categories(df):\n",
    "    df = df.copy()\n",
    "    ord_cols = set(ord_maps.keys())\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'object' and c not in ord_cols:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "X_full = make_categories(X_full)\n",
    "X_test = make_categories(X_test)\n",
    "\n",
    "# ---- FIX: ensure no NaN in categorical columns without double-adding \"None\"\n",
    "for df in (X_full, X_test):\n",
    "    for c in df.columns:\n",
    "        if str(df[c].dtype) == \"category\":\n",
    "            if \"None\" not in df[c].cat.categories:\n",
    "                df[c] = df[c].cat.add_categories([\"None\"])\n",
    "            df[c] = df[c].fillna(\"None\")\n",
    "        elif df[c].dtype == object:\n",
    "            df[c] = df[c].fillna(\"None\")\n",
    "\n",
    "cat_features = [i for i,c in enumerate(X_full.columns) if str(X_full[c].dtype) == \"category\"]\n",
    "\n",
    "# 5) CV + models\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_lgb = np.zeros(len(X_full))\n",
    "oof_cat = np.zeros(len(X_full))\n",
    "pred_lgb = np.zeros(len(X_test))\n",
    "pred_cat = np.zeros(len(X_test))\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective=\"regression\",\n",
    "    metric=\"rmse\",\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=5000,\n",
    "    num_leaves=16,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.3,\n",
    "    min_child_samples=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "    use_catboost = True\n",
    "except Exception:\n",
    "    use_catboost = False\n",
    "\n",
    "cat_params = dict(\n",
    "    loss_function=\"RMSE\",\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=5.0,\n",
    "    iterations=10000,\n",
    "    random_seed=42,\n",
    "    task_type=\"CPU\",\n",
    "    verbose=False,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=200,\n",
    "    allow_writing_files=False\n",
    ")\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kfold.split(X_full), 1):\n",
    "    X_tr, X_va = X_full.iloc[tr_idx], X_full.iloc[va_idx]\n",
    "    y_tr, y_va = y_log[tr_idx], y_log[va_idx]\n",
    "\n",
    "    # LightGBM\n",
    "    dtr = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_features, free_raw_data=False)\n",
    "    dva = lgb.Dataset(X_va, label=y_va, categorical_feature=cat_features, reference=dtr, free_raw_data=False)\n",
    "    m_lgb = lgb.train(\n",
    "        lgb_params,\n",
    "        dtr,\n",
    "        valid_sets=[dtr, dva],\n",
    "        valid_names=[\"train\",\"valid\"],\n",
    "        num_boost_round=5000,\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=300, verbose=False),\n",
    "            log_evaluation(period=200)\n",
    "        ]\n",
    "    )\n",
    "    oof_lgb[va_idx] = m_lgb.predict(X_va, num_iteration=m_lgb.best_iteration)\n",
    "    pred_lgb += m_lgb.predict(X_test, num_iteration=m_lgb.best_iteration) / kfold.n_splits\n",
    "\n",
    "    # CatBoost\n",
    "    if use_catboost:\n",
    "        tr_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n",
    "        va_pool = Pool(X_va, y_va, cat_features=cat_features)\n",
    "        m_cat = CatBoostRegressor(**cat_params)\n",
    "        m_cat.fit(tr_pool, eval_set=va_pool, use_best_model=True, verbose=False)\n",
    "        oof_cat[va_idx] = m_cat.predict(va_pool)\n",
    "        pred_cat += m_cat.predict(Pool(X_test, cat_features=cat_features)) / kfold.n_splits\n",
    "\n",
    "# 6) Blend\n",
    "def rmsle_from_log(y_true_log, y_pred_log):\n",
    "    return np.sqrt(np.mean((y_true_log - y_pred_log)**2))\n",
    "\n",
    "if use_catboost:\n",
    "    best_w, best_score = None, 9e9\n",
    "    for w in np.linspace(0.0, 1.0, 51):\n",
    "        oof_blend = w*oof_lgb + (1-w)*oof_cat\n",
    "        score = rmsle_from_log(y_log, oof_blend)\n",
    "        if score < best_score:\n",
    "            best_score, best_w = score, w\n",
    "    print(f\"[Blend] Best OOF RMSLE (log space): {best_score:.5f} with LightGBM weight={best_w:.2f}\")\n",
    "    test_log = best_w*pred_lgb + (1-best_w)*pred_cat\n",
    "else:\n",
    "    print(\"[Blend] CatBoost unavailable, using LightGBM only.\")\n",
    "    test_log = pred_lgb\n",
    "\n",
    "# 7) Save submission\n",
    "test_preds = np.expm1(test_log)\n",
    "test_preds = np.maximum(test_preds, 0)\n",
    "submission = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": test_preds})\n",
    "out_path = \"/kaggle/working/submission.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.695672,
   "end_time": "2025-10-14T17:34:06.008108",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T17:30:58.312436",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
